{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import librosa\n",
    "import torch\n",
    "import yaml\n",
    "import numpy as np\n",
    "from wandas.core import ChannelFrame\n",
    "# 'model'ディレクトリをPythonのパスに追加\n",
    "from system.sep_system import TwoChSepSystem\n",
    "from models.dcunet import TwoChDCUNet\n",
    "\n",
    "from torchmetrics.audio.snr import (\n",
    "    signal_noise_ratio as snr,\n",
    ")\n",
    "\n",
    "import pytorch_lightning as pl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./DCUNet/conf_finetuning_crosstalk_add_EQ_Large-DCUNet.yml\") as f:\n",
    "    conf = yaml.safe_load(f)\n",
    "\n",
    "model = TwoChDCUNet(\n",
    "    **conf[\"filterbank\"],\n",
    "    **conf[\"masknet\"],\n",
    "    sample_rate=conf[\"data\"][\"sample_rate\"],\n",
    ")\n",
    "\n",
    "def loss_fn(pred, tgt):\n",
    "    return - snr(pred, tgt).mean()\n",
    "\n",
    "system = TwoChSepSystem(\n",
    "        model=model,\n",
    "        loss_func=loss_fn,\n",
    "        optimizer=None,\n",
    "        train_loader=None,\n",
    "        val_loader=None,\n",
    "        scheduler=None,\n",
    "        config=conf,\n",
    "    )\n",
    "\n",
    "state_dict = torch.load(\"./exp/checkpoints/epoch=33-step=340000.ckpt\", weights_only=True, map_location=\"cpu\")\n",
    "system.load_state_dict(state_dict=state_dict[\"state_dict\"])\n",
    "system.cpu()\n",
    "model.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"./data\"\n",
    "source_audio_file = \n",
    "\n",
    "fs = 32000\n",
    "source_signal, _ = librosa.load(os.path.join(data_dir, source_audio_file), sr=fs, duration=10) \n",
    "\n",
    "# Ensure the audio data is in floating-point format\n",
    "source_signal = source_signal.astype(np.float32)\n",
    "source_signal /= np.abs(source_signal).max()*1.2\n",
    "# HPSS\n",
    "#ハーモニック成分を取得\n",
    "source_signal_r = np.copy(source_signal)\n",
    "for i in range(1):\n",
    "    source_signal_r = source_signal_r - librosa.effects.harmonic(source_signal_r,margin=1, kernel_size=62)\n",
    "\n",
    "# Perform STFT\n",
    "D = librosa.stft(source_signal_r)\n",
    "\n",
    "# Separate amplitude and phase\n",
    "amplitude, phase = np.abs(D), np.angle(D)\n",
    "\n",
    "# Modify the amplitude\n",
    "med = np.mean(amplitude, axis=-1, keepdims=True)\n",
    "med_tiled = np.tile(med, (1, amplitude.shape[1]))\n",
    "\n",
    "mask = amplitude <med_tiled \n",
    "amplitude[mask] = 1E-12 \n",
    "# Combine modified amplitude with original phase\n",
    "D_modified = amplitude * np.exp(1j * phase)\n",
    "\n",
    "# Perform inverse STFT  \n",
    "source_signal_r = librosa.istft(D_modified)\n",
    "\n",
    "source_signal_h = source_signal - source_signal_r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mixed, noise = source_signal, np.roll(source_signal_h, int(fs*0.0))*3\n",
    "est_targets = model(torch.stack([torch.from_numpy(mixed.astype(np.float32)), torch.from_numpy(noise.astype(np.float32))], dim=0).unsqueeze(0)).squeeze()\n",
    "est_targets =est_targets.detach().numpy()\n",
    "est_noise = (mixed - est_targets).squeeze()\n",
    "sep_signal = ChannelFrame.from_ndarray(np.stack([source_signal, source_signal_r, est_targets, source_signal_h, est_noise], axis=0), sampling_rate=fs, labels=[\"obs\", \"hpss residual\", \"dnn percussive\", \"hpss harmonic\", \"dnn harmonic\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sep_signal.describe()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
